\documentclass[presentation]{beamer}

\usepackage{tikz}
\usetikzlibrary{positioning,calc}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{backgrounds}% only to show the bounding box
\usetikzlibrary{shapes,arrows}
\usepackage{pgfplots}
\usepackage{pgfplotstable}
\usetikzlibrary{pgfplots.groupplots}
\pgfplotsset{compat=1.12}
\usepackage{appendixnumberbeamer}
\usepackage{amsmath}
\date{27th March 2017}
\usetheme{firedrake}

\pgfplotscreateplotcyclelist{decent cycle}{%
  {blue, mark=*, mark options={fill=blue},
    mark size=2pt},
  {cyan, mark=square*, mark options={fill=cyan},
    mark size=2pt},
  {magenta, mark=triangle*, mark options={fill=magenta},
    mark size=3pt},
  {blue, mark=*, mark options={fill=blue},
    mark size=2pt},
  {cyan, mark=square*, mark options={fill=cyan},
    mark size=2pt},
  {magenta, mark=triangle*, mark options={fill=magenta},
    mark size=3pt},
}

\pgfplotsset{
  decent/.style={
    cycle list name=decent cycle,
  }
}
\renewcommand{\vec}[1]{\ensuremath{\boldsymbol{#1}}}
\newcommand{\ddt}[1]{\frac{\partial #1}{\partial t}}
\newcommand{\zhat}{\hat{\vec{z}}}
\newcommand{\W}{\ensuremath{\mathbb{W}}}

\DeclareMathOperator{\grad}{grad}
\let\div\relax
\DeclareMathOperator{\div}{div}
\DeclareMathOperator{\curl}{curl}

\newcommand{\inner}[1]{\left\langle #1 \right \rangle}

\newcommand{\KSP}[2]{\ensuremath{\mathcal{K}\left(#1, \mathbb{#2}\right)}}
\newcommand{\ksp}[1]{\KSP{#1}{#1}}

\newcommand{\highlight}[1]{\colorbox{red!20}{\color{black} #1}}

\author{Lawrence Mitchell\inst{1,*}}
\institute{
\inst{1}Departments of Computing and Mathematics, Imperial College
London

\inst{*}\texttt{lawrence.mitchell@imperial.ac.uk}
}

\graphicspath{{./\jobname.figures/}}

\newcommand{\arxivlink}[2]{%
  \href{http://www.arxiv.org/abs/#1}%
  {{\small\texttt{arXiv:\,#1\,[#2]}}}%
}
\newcommand{\doilink}[1]{%
  \href{http://dx.doi.org/#1}%
  {{\small\texttt{doi:\,#1}{}}}%
}
\usepackage[url=false,
            doi=true,
            isbn=false,
            style=authoryear,
            firstinits=true,
            uniquename=init,
            backend=biber]{biblatex}

\setbeamertemplate{bibliography item}{}
\renewcommand{\bibfont}{\footnotesize}
\addbibresource{references.bib}

\setlength{\bibitemsep}{1ex}
\setlength{\fboxsep}{1pt}

\renewbibmacro{in:}{}
\DeclareFieldFormat[article]{volume}{\textbf{#1}}
\DeclareFieldFormat{doi}{%
  doi\addcolon%
  {\scriptsize\ifhyperref{\href{http://dx.doi.org/#1}{\nolinkurl{#1}}}
    {\nolinkurl{#1}}}}
\AtEveryBibitem{%
\clearfield{pages}%
\clearfield{issue}%
\clearfield{number}%
}

\usepackage{minted}

\title{Specifying and solving PDEs}
\subtitle{\only<1>{\phantom{$\dots$ easily?}}\only<2>{$\dots$ easily?}}

\begin{document}

\maketitle

\section{Introduction}

\begin{frame}
  \frametitle{Overview}
  Philosophy

  Numerical solution of PDEs using finite elements

  A generative approach

  What did we gain?

  Examples and discussion
\end{frame}

\begin{frame}
  \frametitle{A barrier to progress}
  \begin{lemma}
    Developing sophisticated numerical models ``from scratch'' is a
    lot of work.
  \end{lemma}
  \begin{corollary}
    Many new advances in methods are only tried on simple problems.

    Better numerical methods take a long time to move into ``real
    world'' application domains.
  \end{corollary}
\end{frame}

\begin{frame}
  \frametitle{Why does it happen like this?}
  \begin{itemize}[<+->]
  \item ``I need to solve a PDE''
  \item (search for software that solves my problem)
  \item ``All these libraries are too complicated''
  \item (2 weeks writing code)
  \item ``That was easy''
  \item ``Oh wait, I need parallel/adaptivity/high-order/...''
  \item (3 years writing code)
  \item ``That was easy''
  \end{itemize}

  \begin{uncoverenv}<+>
    We should be able to do better.
  \end{uncoverenv}
\end{frame}

\begin{frame}
  \frametitle{What if?}
  We could focus on what we're interested in.

  And take advantage in advances in sophistication in areas we rely
  on.

  This is, after all, how the sum of human knowledge progresses.
\end{frame}

\begin{frame}
  \frametitle{Building abstractions}
  We make progress in fields when we observe, and exploit, some
  unifying \emph{abstraction}.

  In computational modelling, by capturing abstractions, we can
  devolve much of the tedious work of programming to the computer.

  A guiding principle here is \emph{say what, not how}.
\end{frame}

\begin{frame}[fragile, t]
  \frametitle{In the beginning}
  Compute $y \leftarrow \nabla^2 x$ using finite differences.
  \begin{equation*}
    y_{i,j} = x_{i-1, j} + x_{i+1, j} + x_{i, j-1} + x_{i, j+1} - 4x_{i,j}    
  \end{equation*}

  \begin{onlyenv}<2>
    \begin{block}{Before 1953}
\begin{minted}[fontsize=\tiny]{asm}
        ...
        faddp   %st, %st(1)
        movl    -8(%ebp), %edx
        movl    %edx, %eax
        sall    $2, %eax
        addl    %edx, %eax
        leal    0(,%eax,4), %edx
        addl    %edx, %eax
        sall    $2, %eax
        movl    %eax, %edx
        movl    -4(%ebp), %eax
        addl    %edx, %eax
        subl    $101, %eax
        flds    x.3305(,%eax,4)
        flds    .LC0
        fmulp   %st, %st(1)
        faddp   %st, %st(1)
        fstps   y.3307(,%ecx,4)
        ...
\end{minted}
    \end{block}
  \end{onlyenv}
  \begin{onlyenv}<3->
    \begin{block}{After 1953}
\begin{minted}[fontsize=\tiny]{fortran}
      PROGRAM MAIN
      PARAMETER (N=100)
      REAL X(N,N), Y(N,N)
      DO 10 J=2,N-1
         DO 20 I=2,N-1
            Y(I,J)=X(I-1,J)+X(I+1,J)+X(I,J-1)+X(I,J+1)+4*X(I,J)
 20      CONTINUE
 10   CONTINUE
      DO 30 I=1,N
         Y(I,1) = 0.0
         Y(I,N) = 0.0
         Y(1,I) = 0.0
         Y(N,I) = 0.0
 30   CONTINUE
      END
\end{minted}
    \end{block}
    \only<4>{The same code runs on different machines}
  \end{onlyenv}
\end{frame}

\begin{frame}
  \frametitle{If only}
  If only everything were so simple.

  FD bad for unstructured geometries

  High-order discretisations not systematic

  Was that implementation even efficient?
\end{frame}

\section{Solving PDEs}

\begin{frame}[allowframebreaks]
  \frametitle{Finite element crash course}
  \begin{align*}
    F(u) &= 0 \text{ in $\Omega$}\\
    u &= g \text{ on $\Gamma_1$}\\
    \frac{\partial u}{\partial n} &= h \text{ on $\Gamma_2$}
  \end{align*}
  Seek \emph{weak} solution in some space of functions $V(\Omega)$.

  Find $u\in V$ s.t.
\begin{equation*}
\int_\Omega \!F(u) v\, \text{d}x = 0 \quad \forall\, v \in V
\end{equation*}
Choose discrete $V_h \subset V$, and seek $u_h \in V_h$.

Pick \emph{basis} for $V_h$ with finite support.

\pagebreak
Divide domain $\Omega$ into triangulation $\mathcal{T}$.

Integrals become sum over element integrals
\begin{equation*}
  \int_\Omega\! F(u_h) v_h \, \text{d}x =
  \sum_{e \in \mathcal{T}} \int_e\! F(u_h)v_h\, \text{d}x
\end{equation*}

Perform element integrals with numerical quadrature
\begin{equation*}
  \int_e F(u_h)v_h\,\text{d}x = \sum_q w_q F(u_h(q)) v_h(q)\,\text{d}x
\end{equation*}

$F(u_h(q))$ is ``user-specified''.  Variability in innermost loop.
\end{frame}


\begin{frame}
  \frametitle{Added complexity}
  Compared to the simple finite difference code, I need much more code

  \begin{itemize}
  \item Numerical quadrature
  \item Orthogonal polynomials
  \item Indirections from elements to data
  \end{itemize}

  I can't fit the action of the laplacian on a slide any more.

  
  Straightforward fortran isn't a scalable answer.  But, if we can
  find the abstract idea, then we can capture it in a \emph{library}.

  Successful examples

  \begin{itemize}
  \item BLAS
  \item LAPACK
  \item PETSc
  \item Matlab
  \item R
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{When are mathematical abstractions successful?}

  Atomic unit of computation is \emph{large}, so cost of serialising
  data access is small.

  e.g. Reference BLAS: build BLAS-3 out of BLAS-2 out of BLAS-1

  Actual BLAS: Build BLAS-3 out of optimised code (calling BLAS-2 and
  BLAS-1 operations too expensive).
\end{frame}

\section{What if$\dots$}

\begin{frame}[fragile]
  \begin{columns}
    \begin{column}{0.48\framewidth}
      \begin{block}{Rayleigh-B\'enard convection}
        \small
        \begin{equation*}
          \begin{split}
            -\Delta u + u\cdot\nabla u + \nabla p +
            \frac{\text{Ra}}{\text{Pr}} \hat{g}T &= 0 \\
            \nabla \cdot u &= 0 \\
            - \frac{1}{\text{Pr}} \Delta T + u\cdot \nabla T &= 0
          \end{split}
        \end{equation*}
      \end{block}
    \end{column}
    \begin{column}{0.52\framewidth}
\begin{minted}[fontsize=\tiny,mathescape]{python}
from firedrake import *
mesh = Mesh(...)
V = VectorFunctionSpace(mesh, "CG", 2)
W = FunctionSpace(mesh, "CG", 1)
Q = FunctionSpace(mesh, "CG", 1)
Z = V * W * Q
upT = Function(Z)
u, p, T = split(upT)
v, q, S = TestFunctions(Z)
bcs = [...] # no-flow + temp gradient
nullspace = MixedVectorSpaceBasis(
   Z, [Z.sub(0), VectorSpaceBasis(constant=True), 
       Z.sub(2)])
F = (inner(grad(u), grad(v))
     + inner(dot(grad(u), u), v)
     - inner(p, div(v))
     + (Ra/Pr)*inner(T*g, v)
     + inner(div(u), q)
     + inner(dot(grad(T), u), S)
     + (1/Pr) * inner(grad(T), grad(S)))*dx

solve(F == 0, upT, bcs=bcs, nullspace=nullspace)
\end{minted}
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}
  \frametitle{What about solving PDEs}
  \emph{Simple} finite difference models can be programmed from scratch.

  No-one should attempt to write a finite element model from
  scratch. Pick a library:
  \begin{center}
    \small
    \begin{tabular}{lr}
      deal.II   & \url{www.dealii.org}            \\
      DUNE      & \url{www.dune-project.org}      \\
      Firedrake & \url{www.firedrakeproject.org}  \\
      FEniCS    & \url{www.fenicsproject.org}     \\
      FreeFEM++ & \url{www.freefem.org}           \\
      Feel++    & \url{www.feelpp.org}            \\
      MFEM      & \url{mfem.org}                  \\
      NGSolve   & \url{ngsolve.org}               \\
      oomph-lib & \url{oomph-lib.maths.man.ac.uk} \\
      ...       &                                 \\
    \end{tabular}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{Why so many?}
  Finite element method lends itself to software libraries.
  
  Strong set of mathematical abstractions.  Typically mirrored (in one
  way or another) in the numerical library.
\end{frame}

\begin{frame}[allowframebreaks]
  \frametitle{Finite element crash course}
  Want to solve some PDE $F(u) = 0 \quad \text{in}\:\Omega$

  Seek \emph{weak} solution in some space of functions $V(\Omega)$.  Find $u\in
  V$ s.t.
\begin{equation*}
\int_\Omega \!F(u) v\, \text{d}x = 0 \quad \forall\, v \in V
\end{equation*}
Choose discrete $V_h \subset V$, and seek $u_h \in V_h$.

Pick \emph{basis} for $V_h$ with finite support.

\pagebreak
Divide domain $\Omega$ into elements $E$.

Integrals become sum over element integrals
\begin{equation*}
\int_\Omega\! F(u_h) v_h \, \text{d}x = \sum_{e \in E} \int_e\! F(u_h)v_h\, \text{d}x
\end{equation*}

Perform element integrals with numerical quadrature
\begin{equation*}
  \int_e F(u_h)v_h\,\text{d}x = \sum_q w_q F(u_h(q)) v_h(q)\,\text{d}x
\end{equation*}

$F(u_h(q))$ is ``user-specified''.  Variability in innermost loop.
\end{frame}

\begin{frame}
  \frametitle{Computational model}
  Abstract model for computing a finite element
  integral:
  \begin{enumerate}
  \item \emph{gather} from global to local
  \item \emph{compute} on local data
  \item \emph{scatter} from local to global
  \end{enumerate}

  Software libraries provide APIs for each of these steps.
\end{frame}
\begin{frame}[fragile]
  You might write code like this.
\begin{minted}[fontsize=\tiny]{cpp}
template<typename EG, typename LFSU, typename X, typename LFSV, typename M>
void jacobian_volume(const EG& eg, const LFSU& lfsu, const X& x, 
                     const LFSV& lfsv, M& mat) const {
  const auto geo = eg.geometry();
  const auto S = geo.jacobianInverseTransposed(qp);
  RF factor = weight*geo.integrationElement(qp);
  double grad[dim][n] = {{0.0}};
  for (int i=0; i<dim; i++)
    for (int k=0; k<dim; k++)
      for (int j=0; j<n; j++)
        grad[i][j] += S[i][k] * gradhat[k][j];
  double A[n][n] = {{0.0}};
  for (int i=0; i<n; i++)
    for (int k=0; k<dim; k++)
      for (int j=0; j<n; j++)
        A[i][j] += grad[k][i]*grad[k][j];
  for (int i=0; i<n; i++)
    for (int j=0; j<n; j++)
      mat.accumulate(lfsu,i,lfsu,j,A[i][j]*factor);
}
\end{minted}
\end{frame}
\begin{frame}
  \frametitle{Difficult to see the numerics}
  \begin{itemize}
  \item \emph{Implementation} details mixed in with numerics
  \item To change numerics, requires \emph{understanding} the
    low-level implementation.
  \item User code is (mostly) opaque to the library.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \begin{block}{Assertion}
    Once we pick the discretisation, writing the element integral is mechanical.
  \end{block}
  \begin{corollary}
    Computers are good at mechanical things, why don't we get the
    computer to write the element integral?
  \end{corollary}
  \begin{uncoverenv}<2>
    \begin{center}
\begin{minted}[fontsize=\tiny]{python}
V = FiniteElement("Lagrange", tetrahedron, 1)
u = TrialFunction(V)
v = TestFunction(V)
a = dot(grad(u), grad(v))*dx
k, = compile_form(a)
\end{minted}
    \end{center}
  \end{uncoverenv}
\end{frame}

\begin{frame}[fragile]
\begin{minted}[fontsize=\tiny]{c}
void cell_integral(double A[4][4], const double *const restrict *restrict coords) {
  static const double  t23[4]  = {-1.0, 0.0, 0.0, 1.0};
  static const double  t25[4]  = {-1.0, 0.0, 1.0, 0.0};
  static const double  t27[4]  = {-1.0, 1.0, 0.0, 0.0};
  ... /* Part of unrolled Jacobian computation */
  double t0  = (-1 * coords[0][0]);
  double t1  = (t0 + coords[1][0]);
  double t2  = (-1 * coords[0][1]);
  double t3  = (t2 + coords[2][1]);
  double t4  = (-1 * coords[0][2]);
  double t5  = (t4 + coords[3][2]);
  double t6  = (t2 + coords[3][1]);
  double t7  = (t4 + coords[2][2]);
  ...
  double t31  = (0.166666666666667 * fabs(t15));
  for (int k0 = 0; k0 < 4; k0++) {
    t28[k0] = ((t26 * t27[k0]) + (t24 * t25[k0])) + (t22 * t23[k0]);
    t29[k0] = ((t21 * t27[k0]) + (t20 * t25[k0])) + (t19 * t23[k0]);
    t30[k0] = ((t18 * t27[k0]) + (t17 * t25[k0])) + (t16 * t23[k0]);
  }
  for (int j0 = 0; j0 < 4; j0++) {
    double t32  = (((t26 * t27[j0]) + (t24 * t25[j0])) + (t22 * t23[j0]));
    double t33  = (((t21 * t27[j0]) + (t20 * t25[j0])) + (t19 * t23[j0]));
    double t34  = (((t18 * t27[j0]) + (t17 * t25[j0])) + (t16 * t23[j0]));
    for (int  k0  = 0; k0 < 4; k0 += 1) {
      A[j0][k0] += t31 * (((t34 * t30[k0]) + (t33 * t29[k0])) + (t32 * t28[k0]));
    }
  }
}
\end{minted}
\end{frame}

\begin{frame}
  \frametitle{Automated finite elements}
  Use domain specific language to specify finite element problem.

  The \emph{Unified Form Language} \parencite{Alnaes:2014} is exactly
  that.

  It provides a DSL for finite element variational forms embedded in
  Python.

  Purely symbolic.

  Problem specification language for both FEniCS and Firedrake.
\end{frame}

\begin{frame}
  \frametitle{Automated finite elements}
  A \emph{form compiler} transforms this symbolic description to a low
  level implementation of the element integral.

  There are a few of these:

  \begin{itemize}
  \item DUNE: form compiler in development
  \item FFC: the FEniCS form compiler
  \item TSFC: the two stage form compiler
  \item SyFI: abandonware...
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Adding global data}
  Two options:
  \begin{enumerate}
  \item Write mesh iteration code ``by hand'' (it's easy) and
    incorporate generated element code.
  \item Notice that the mesh iteration code is also mechanical, so why
    don't we get the computer to write it.
  \end{enumerate}

  Firedrake does the latter
\end{frame}

\begin{frame}[fragile]
  \frametitle{If I have a compiler}
  Naive residual assembly costs $\mathcal{O}(p^{2d})$ operations.

  Structured basis (e.g. on hexahedra) can reduce this to $\mathcal{O}(p^{d + 1})$.
\begin{minted}[fontsize=\tiny]{python}
V = FiniteElement("Lagrange", hexhedron, 7)
u = Coefficient(V)
v = TestFunction(V)
count_flops(dot(grad(u), grad(v))*dx(metadata={"mode": "vanilla"}))  => 6668201
count_flops(dot(grad(u), grad(v))*dx(metadata={"mode": "spectral"})) =>  185257
\end{minted}
\end{frame}

\begin{frame}
  \frametitle{A job for an expert}
  Hardware-aware optimsation of finite element kernels is a job for:
  \begin{itemize}
  \item<2-> A numerical analyst?
  \item<3-> A geodynamicist?
  \item<4-> A computational chemist?
  \item<5-> A computational scientist?
  \item<6-> A computer scientist?
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Human compilers}
  \begin{problem}<+->
    Modern optimising compilers do a bad job on finite element
    kernels.
  \end{problem}
  \begin{corollary}<+->
    We spoon-feed the compiler already optimised code on a case by
    case basis.
  \end{corollary}
\end{frame}
  
\begin{frame}
  \frametitle{Automating expertise}
  You can perform these optimisations by hand, but
  
  \begin{itemize}
  \item ``In-person'' case-by-case optimisation \emph{does not scale}
  \item Code generation allows us to package expertise and provide it
    to everyone
  \item Done by a special-purpose kernel compiler
  \item Anecdotally, research groups that have implemented ``high
    performance'' finite element code by hand, are now turning to
    domain compilers
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Firedrake team}
  \begin{center}
    \url{www.firedrakeproject.org}\\
    \cite{Rathgeber:2016} \arxivlink{1501.01809}{cs.MS}
  \end{center}

  \begin{itemize}
  \item[IC] Thomas Gibson, David A.~Ham, Mikl\'os Homolya, {\color{gray}Fabio
    Luporini}, Tianjiao Sun, Paul H.~J.~Kelly
  \item[Bath] Andrew T.~T.~McRae
  \item[\color{gray}ECMWF] \color{gray}Florian Rathgeber
  \item[\color{gray}IBM] \color{gray}Gheorghe-Teodor Bercea
  \end{itemize}
\end{frame}


\begin{frame}[fragile]
  \frametitle{Software libraries simplify writing models}
  \begin{columns}
    \begin{column}{0.48\framewidth}
      \begin{block}{Stationary Rayleigh-B\'enard convection}
        \begin{equation*}
          \begin{split}
            -\Delta u + u\cdot\nabla u + \nabla p +
            \frac{\text{Ra}}{\text{Pr}} \hat{g}T &= 0 \\
            \nabla \cdot u &= 0 \\
            - \frac{1}{\text{Pr}} \Delta T + u\cdot \nabla T &= 0
          \end{split}
        \end{equation*}
      \end{block}
    \end{column}
    \begin{column}{0.52\framewidth}
\begin{minted}[fontsize=\tiny,mathescape]{python}
from firedrake import *
mesh = Mesh(...)
V = VectorFunctionSpace(mesh, "CG", 2)
W = FunctionSpace(mesh, "CG", 1)
Q = FunctionSpace(mesh, "CG", 1)
Z = V * W * Q
upT = Function(Z)
u, p, T = split(upT)
v, q, S = TestFunctions(Z)
bcs = [...] # no-flow + temp gradient
nullspace = MixedVectorSpaceBasis(
   Z, [Z.sub(0), VectorSpaceBasis(constant=True), 
       Z.sub(2)])
F = (inner(grad(u), grad(v))
     + inner(dot(grad(u), u), v)
     - inner(p, div(v))
     + (Ra/Pr)*inner(T*g, v)
     + inner(div(u), q)
     + inner(dot(grad(T), u), S)
     + (1/Pr) * inner(grad(T), grad(S)))*dx

solve(F == 0, upT, bcs=bcs, nullspace=nullspace)
\end{minted}
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Symbolic, numerical computing}
  Weave together
  \begin{itemize}
  \item \emph{symbolic} problem description
\begin{minted}[fontsize=\tiny]{python}
Z = V * W * Q
upT = Function(Z)
u, p, T = split(upT)
v, q, S = TestFunctions(Z)
F = (inner(grad(u), grad(v))
     + inner(dot(grad(u), u), v)
     - inner(p, div(v))
     + (Ra/Pr)*inner(T*g, v)
     + inner(div(u), q)
     + inner(dot(grad(T), u), S)
     + (1/Pr) * inner(grad(T), grad(S)))*dx
\end{minted}
  \item with problem-specific data (which mesh, what solver?)
\begin{minted}[fontsize=\tiny]{python}
mesh = Mesh(...)
V = VectorFunctionSpace(mesh, "CG", 2)
W = FunctionSpace(mesh, "CG", 1)
Q = FunctionSpace(mesh, "CG", 1)
bcs = [...] # no-flow + temp gradient
nullspace = MixedVectorSpaceBasis(
   Z, [Z.sub(0), VectorSpaceBasis(constant=True), 
       Z.sub(2)])
solve(F == 0, u, bcs=bcs, solver_parameters=...)
\end{minted}
  \end{itemize}
  and \emph{synthesise} efficient implementation from
  the symbolic problem description.
\end{frame}

\appendix
\begin{frame}[t]
  \frametitle{References}
  \printbibliography[heading=none]
\end{frame}

\end{document}
